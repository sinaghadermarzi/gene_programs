{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinagh/Documents/anaconda/anaconda3/envs/gprog/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/sinagh/Documents/anaconda/anaconda3/envs/gprog/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/sinagh/Documents/anaconda/anaconda3/envs/gprog/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/sinagh/Documents/anaconda/anaconda3/envs/gprog/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mnist\")\n",
    "dataset.set_format('numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1d = np.array([dataset['train'][i]['image'].flatten() for i in range(len(dataset['train']))])\n",
    "labels= dataset['train']['label']\n",
    "img_shape= dataset['train'][0]['image'].shape\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projecting data into pre-defined programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each digit, we will plot the average of pixels from the images belonging to that digit\n",
    "imgs_grouped_by_label = [dataset['train']['image'][labels == i] for i in range(10)]\n",
    "avg_img = [imgs_grouped_by_label[i].mean(axis=0) for i in range(10)]\n",
    "digit_programs = [avg_img[i].flatten() for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building KNN graph for mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scanpy as sc\n",
    "import anndata \n",
    "import scanpy as sc\n",
    "mnist_adata = anndata.AnnData(X= img1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Youâ€™re trying to run this on 784 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinagh/Documents/anaconda/anaconda3/envs/gprog/lib/python3.11/site-packages/anndata/_core/anndata.py:522: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sc.pp.neighbors(mnist_adata,n_neighbors=5)\n",
    "mnist_adata.obsp['connectivities']\n",
    "edge_list = mnist_adata.obsp['connectivities'].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from datasets import load_dataset\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "import pandas as pd\n",
    "from models import geneprog_encoder_linear\n",
    "from datasets import load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from torch_geometric.loader import GraphSAINTRandomWalkSampler\n",
    "from torch_geometric.data import Data\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_node_features: int, hidden_dim: int, output_dim: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=dropout)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index): \n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.act1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "def visualize_graph(G, color):\n",
    "    # fig_num  = randint(0,10000)\n",
    "    # plt.figure(num=fig_num,figsize=(7,7))\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, pos=nx.spring_layout(G, scale= 20, seed=42), ax = ax, with_labels=False,\n",
    "                     node_color=color, node_size=10,linewidths=1, cmap=\"Set2\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def visualize_embedding(h, color, epoch=None, loss=None):\n",
    "    fig_num  = randint(0,10000)\n",
    "    plt.figure(num=fig_num,figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    h = h.detach().cpu().numpy()\n",
    "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "    if epoch is not None and loss is not None:\n",
    "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
    "    return plt.figure(fig_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "import torch.nn as nn\n",
    "from models import geneprog_encoder_MLP\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim: int, hidden_dim: int, out_dim: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        # self.conv1 = GCNConv(in_dim, in_dim)\n",
    "        # self.mlp = geneprog_encoder_MLP(in_dim,out_dim)\n",
    "\n",
    "        self.conv1 = GCNConv(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, edge_index): \n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        # x = self.mlp(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sinagh/local_work/gene_programs/gene_programs/wandb/run-20240206_173553-rdh0ynhq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sinag/gene_programs/runs/rdh0ynhq' target=\"_blank\">GCN_2024_02_06___17_35_49</a></strong> to <a href='https://wandb.ai/sinag/gene_programs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sinag/gene_programs' target=\"_blank\">https://wandb.ai/sinag/gene_programs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sinag/gene_programs/runs/rdh0ynhq' target=\"_blank\">https://wandb.ai/sinag/gene_programs/runs/rdh0ynhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 119\u001b[0m\n\u001b[1;32m    115\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(batch_labels_cpu,top_prg)\n\u001b[1;32m    118\u001b[0m temp_cross_ents\u001b[38;5;241m.\u001b[39mappend(crossent_val)\n\u001b[0;32m--> 119\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_true\u001b[38;5;241m=\u001b[39mbatch_labels_cpu, y_score\u001b[38;5;241m=\u001b[39mproba_cpu, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m,labels\u001b[38;5;241m=\u001b[39mlabel_list)\n\u001b[1;32m    122\u001b[0m r2_value \u001b[38;5;241m=\u001b[39m r2_score(flattened_x, flattened_reconst)\n\u001b[1;32m    123\u001b[0m pearson_r_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcorrcoef(flattened_x, flattened_reconst)[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/gprog/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:566\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _multiclass_roc_auc_score(\n\u001b[1;32m    567\u001b[0m         y_true, y_score, labels, multi_class, average, sample_weight\n\u001b[1;32m    568\u001b[0m     )\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    570\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/gprog/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:703\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# ovr is same as multi-label\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     y_true_multilabel \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mclasses)\n\u001b[0;32m--> 703\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    704\u001b[0m         _binary_roc_auc_score,\n\u001b[1;32m    705\u001b[0m         y_true_multilabel,\n\u001b[1;32m    706\u001b[0m         y_score,\n\u001b[1;32m    707\u001b[0m         average,\n\u001b[1;32m    708\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    709\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/gprog/lib/python3.11/site-packages/sklearn/metrics/_base.py:118\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m     y_true_c \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    117\u001b[0m     y_score_c \u001b[38;5;241m=\u001b[39m y_score\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m--> 118\u001b[0m     score[c] \u001b[38;5;241m=\u001b[39m binary_metric(y_true_c, y_score_c, sample_weight\u001b[38;5;241m=\u001b[39mscore_weight)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Average the results\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/anaconda/anaconda3/envs/gprog/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:339\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    344\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "program_def = digit_programs\n",
    "tru_labels = labels\n",
    "WANDB_LOGGING = True\n",
    "LEARNING_RATE = 0.0005\n",
    "WEIGHT_DECAY = 1e-5\n",
    "N_EPOCHS = 250\n",
    "OUTPUT_PREFIX = \"./gene_program_runs\"\n",
    "\n",
    "label_list  = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "datetimestamp = datetime.now().strftime(r'%Y_%m_%d___%H_%M_%S')\n",
    "RUN_NAME = f\"GCN_{datetimestamp}\"\n",
    "\n",
    "\n",
    "\n",
    "SAVE_DIR = os.path.join(OUTPUT_PREFIX, RUN_NAME)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "device = torch.device('mps:0')\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(img1d)\n",
    "mnist_x = torch.tensor(X, dtype=torch.float)\n",
    "mnist_labels = torch.tensor(labels, dtype=torch.long)\n",
    "mnist_edge_list = torch.tensor(edge_list, dtype=torch.long)\n",
    "prog_def_tensor = torch.tensor(digit_programs, dtype=torch.float).to(device)\n",
    "data = Data(x=mnist_x, edge_index=mnist_edge_list,y=mnist_labels)\n",
    "num_cells, num_genes = data.x.shape\n",
    "num_prog, _ = prog_def_tensor.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = GCN(num_genes,num_genes,num_prog,dropout=0.6).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "\n",
    "# GraphSAINT hyperparameters\n",
    "NUM_MINIGRAPH_INPUTS_PER_EPOCH = 20  # Defining length of an epoch here\n",
    "NUMBER_OF_RANDOM_WALKS = 100  # This is dependent on GPU memory constraints\n",
    "RANDOM_WALK_LENGTH = 0\n",
    "\n",
    "\n",
    "loader = GraphSAINTRandomWalkSampler(\n",
    "    data, \n",
    "    batch_size=NUMBER_OF_RANDOM_WALKS, \n",
    "    walk_length=RANDOM_WALK_LENGTH,\n",
    "    num_steps=NUM_MINIGRAPH_INPUTS_PER_EPOCH, \n",
    "    sample_coverage=100,  # leave this as 100, has to do with calculating statistics on initial loading\n",
    "    log=False\n",
    ")\n",
    "\n",
    "# NeighborSampler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "iterations_per_anneal_cycle = N_EPOCHS #// 5  # 5 cosine decays during training\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=iterations_per_anneal_cycle, eta_min=1e-7)\n",
    "\n",
    "# Initialize WandB\n",
    "if WANDB_LOGGING:\n",
    "    curr_run = wandb.init(\n",
    "        project=\"gene_programs\",\n",
    "        entity=\"sinag\",\n",
    "        name=RUN_NAME\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    temp_loss = []\n",
    "    temp_pearson_r = []\n",
    "    temp_r2_score = []\n",
    "    temp_cross_ents = []\n",
    "    temp_auc = []\n",
    "    temp_acc = []\n",
    "    model.train()\n",
    "\n",
    "    for idx, subgraph in enumerate(loader):   \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ### Visualize the graph\n",
    "        # G = to_networkx(subgraph, to_undirected=True)\n",
    "        # fig = visualize_graph(G, color=subgraph.y)\n",
    "        # fig.savefig(os.path.join(SAVE_DIR, f\"graph_epoch_{epoch}_idx_{idx}.png\"), dpi=300)\n",
    "        # plt.close()\n",
    "        ####\n",
    "\n",
    "        subgraph = subgraph.to(device)\n",
    "        batch_program_scores = model(subgraph.x,subgraph.edge_index)  # shape: [cells, gene_programs]\n",
    "\n",
    "        X_reconst = torch.matmul(batch_program_scores, prog_def_tensor)  # [cells, gene_programs] x [gene_programs, num_genes]\n",
    "        loss = criterion(subgraph.x, X_reconst)\n",
    "        loss.backward()\n",
    "\n",
    "        proba = batch_program_scores.softmax(dim=1)\n",
    "\n",
    "        flattened_x = subgraph.x.flatten().detach().cpu().numpy()\n",
    "        flattened_reconst = X_reconst.flatten().detach().cpu().numpy()\n",
    "\n",
    "        proba_cpu = proba.detach().cpu().numpy()\n",
    "        batch_labels_cpu = subgraph.y.detach().cpu().numpy()\n",
    "\n",
    "        crossent_val = log_loss(y_true=batch_labels_cpu, y_pred=proba_cpu,labels=label_list)\n",
    "        top_prg = np.argmax(proba_cpu,axis = 1)\n",
    "        acc = accuracy_score(batch_labels_cpu,top_prg)\n",
    "\n",
    "        \n",
    "        temp_cross_ents.append(crossent_val)\n",
    "        auc = roc_auc_score(y_true=batch_labels_cpu, y_score=proba_cpu, multi_class='ovr',labels=label_list)\n",
    "\n",
    "\n",
    "        r2_value = r2_score(flattened_x, flattened_reconst)\n",
    "        pearson_r_value = np.corrcoef(flattened_x, flattened_reconst)[0, 1]\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        \n",
    "        temp_acc.append(acc)\n",
    "        temp_auc.append(auc)\n",
    "        temp_pearson_r.append(pearson_r_value)\n",
    "        temp_r2_score.append(r2_value)\n",
    "        temp_loss.append(loss_val)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch + idx / len(loader)) # Adjust learning rate\n",
    "\n",
    "\n",
    "    # Compute metrics\n",
    "    avg_auc = np.mean(temp_auc)\n",
    "    avg_acc = np.mean(temp_acc)\n",
    "    avg_loss = np.mean(temp_loss)\n",
    "    avg_r2_score = np.mean(temp_r2_score)\n",
    "    avg_pearsonr_score = np.mean(temp_pearson_r)\n",
    "    avg_crossent = np.mean(temp_cross_ents)\n",
    "\n",
    "    if WANDB_LOGGING:\n",
    "        wandb.log({\n",
    "            \"Learning Rate\": scheduler.get_last_lr()[0],\n",
    "            \"Loss (MSE-reconstruction)\": avg_loss,\n",
    "            \"R2 (reconstruction)\": avg_r2_score,\n",
    "            \"Pearson (reconstruction)\": avg_pearsonr_score,\n",
    "            \"Cross Entropy (program scores - labels)\": avg_crossent,\n",
    "            \"AUC (program scores vs labels)\": avg_auc,\n",
    "            \"Accuracy (top program vs labels)\": avg_acc\n",
    "        }, step=epoch)\n",
    "\n",
    "if WANDB_LOGGING:\n",
    "    curr_run.finish()\n",
    "\n",
    "# model.eval()\n",
    "# program_scores = model(torch.from_numpy(X).to(device))\n",
    "# reconst_all = torch.matmul(program_scores, prog_def_tensor)\n",
    "# program_scores = program_scores.detach().cpu().numpy()\n",
    "# reconst_all = reconst_all.detach().cpu().numpy()\n",
    "\n",
    "# torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('gprog')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "35599c48b48953abcc77e7c8f4f0bb6bc5f6e8addf08818e019c4c71cbe38271"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
